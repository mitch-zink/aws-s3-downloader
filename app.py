import streamlit as st
import boto3
from botocore.exceptions import NoCredentialsError, PartialCredentialsError, ClientError
from botocore.client import Config
from botocore import UNSIGNED
import os


def main():
    st.set_page_config(
        page_title="S3 Bucket Downloader",
        page_icon="üì¶",
        layout="wide",
        initial_sidebar_state="expanded",
    )
    st.title("üì¶ S3 Bucket Downloader")

    with st.sidebar:
        st.header("Configuration ‚öôÔ∏è")
        aws_access_key_id = st.text_input(
            "AWS Access Key ID üîë",
            placeholder="AKIAIOSFODNN7EXAMPLE",
            type="password",
        )
        aws_secret_access_key = st.text_input(
            "AWS Secret Access Key üîí",
            type="password",
            placeholder="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY",
        )
        aws_region = st.text_input("AWS Region üåç", placeholder="us-west-2")
        role_arn = st.text_input(
            "Role ARN üõ°Ô∏è (Optional)",
            placeholder="arn:aws:iam::123456789012:role/RoleName",
        )
        bucket_name = st.text_input("Bucket Name ü™£", placeholder="my-s3-bucket")
        s3_path_prefix = st.text_input(
            "S3 Path Prefix (Optional) üìÅ", placeholder="path/to/folder/"
        )
        local_directory = st.text_input(
            "Local Directory Path üìÇ", placeholder="C:/Users/username/Downloads"
        )

        download_files = st.button("Download All Files üì•")

    s3_client = None
    if aws_region:
        try:
            if role_arn:
                # Assume role
                if not aws_access_key_id or not aws_secret_access_key:
                    st.error(
                        "AWS Access Key ID and Secret Access Key are required to assume a role"
                    )
                    return

                sts_client = boto3.client(
                    "sts",
                    aws_access_key_id=aws_access_key_id,
                    aws_secret_access_key=aws_secret_access_key,
                    region_name=aws_region,
                )

                assumed_role = sts_client.assume_role(
                    RoleArn=role_arn, RoleSessionName="AssumeRoleSession"
                )

                credentials = assumed_role["Credentials"]

                s3_client = boto3.client(
                    "s3",
                    aws_access_key_id=credentials["AccessKeyId"],
                    aws_secret_access_key=credentials["SecretAccessKey"],
                    aws_session_token=credentials["SessionToken"],
                    region_name=aws_region,
                )

            elif aws_access_key_id and aws_secret_access_key:
                # Use provided credentials
                s3_client = boto3.client(
                    "s3",
                    region_name=aws_region,
                    aws_access_key_id=aws_access_key_id,
                    aws_secret_access_key=aws_secret_access_key,
                )
            else:
                # Use default credentials
                s3_client = boto3.client(
                    "s3",
                    region_name=aws_region,
                )
        except (NoCredentialsError, PartialCredentialsError) as e:
            st.error(f"Error with AWS credentials: {str(e)}")
            return
        except ClientError as e:
            st.error(f"Client error: {str(e)}")
            return
    else:
        st.error("Please provide the AWS Region")
        return

    if s3_client and bucket_name and local_directory and download_files:
        try:
            if not os.path.exists(local_directory):
                os.makedirs(local_directory)

            paginator = s3_client.get_paginator("list_objects_v2")
            pages = paginator.paginate(Bucket=bucket_name, Prefix=s3_path_prefix)

            for page in pages:
                if "Contents" in page:
                    for file in page["Contents"]:
                        file_key = file["Key"]
                        if not file_key.endswith(
                            "/"
                        ):  # Checking that it's not a directory
                            # Create local directories if needed
                            relative_path = (
                                file_key[len(s3_path_prefix) :]
                                if s3_path_prefix
                                else file_key
                            )
                            local_file_path = os.path.join(
                                local_directory, relative_path
                            )
                            local_file_dir = os.path.dirname(local_file_path)
                            if not os.path.exists(local_file_dir):
                                os.makedirs(local_file_dir)
                            s3_client.download_file(
                                bucket_name, file_key, local_file_path
                            )
            st.success(f"Downloaded all files to {local_directory}")
        except ClientError as e:
            if e.response["Error"]["Code"] == "403":
                st.error("Access denied to the bucket or object")
            elif e.response["Error"]["Code"] == "404":
                st.error("The bucket or object does not exist")
            else:
                st.error(f"Failed to download files: {str(e)}")
        except Exception as e:
            st.error(f"Failed to download files: {str(e)}")


if __name__ == "__main__":
    main()
